---
title: "DATA 607: W10 Presentation - Jazz Musicians: TF-IDF Example"
author: "Walt Wells, Fall 2016"
output:
  html_document:
    theme: lumen
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

Our goal is to roughly show how to accomplish the "Example: Jazz Musicians" section of Chapter 10 of [Data Science for Business](https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323), using R.

# Environment Prep
```{r, warning=FALSE, message=FALSE}
if (!require('RCurl')) install.packages('RCurl')
if (!require('XML')) install.packages('XML')
if (!require('tm')) install.packages('tm')
if (!require('stringr')) install.packages('stringr')
if (!require('SnowballC')) install.packages('SnowballC')
if (!require('wordcloud')) install.packages('wordcloud')
if (!require('lsa')) install.packages('lsa')
```

# Data Acquisition and Prep

## Data Acquisition

```{r, cache=TRUE}
# function to grab only text in paragraphs
gettext <- function(url) {
    init <- getURLContent(url) 
    parsed <- htmlParse(init)
    ready <- xpathApply(parsed, '//p', xmlValue)
    ready <- gsub('\\n', ' ', ready)
    ready <- paste(ready, sep = "", collapse = "")
    ready
}

# get info from wiki
if (!exists('cParker')) cParker <- gettext("https://en.wikipedia.org/wiki/Charlie_Parker")
if (!exists('mDavis')) mDavis <- gettext("https://en.wikipedia.org/wiki/Miles_Davis")
if (!exists('dEllington')) dEllington <- gettext("https://en.wikipedia.org/wiki/Duke_Ellington")
if (!exists('jColtrane')) jColtrane <- gettext("https://en.wikipedia.org/wiki/John_Coltrane")
if (!exists('dGillespie')) dGillespie <- gettext("https://en.wikipedia.org/wiki/Dizzy_Gillespie")
if (!exists('lArmstrong')) lArmstrong <- gettext("https://en.wikipedia.org/wiki/Louis_Armstrong")
if (!exists('cHawkins')) cHawkins <- gettext("https://en.wikipedia.org/wiki/Coleman_Hawkins")
if (!exists('cMingus')) cMingus <- gettext("https://en.wikipedia.org/wiki/Charles_Mingus")
```

## Data Prep and Clean

```{r, cache=TRUE}
# setup vector for later
list <- c("Charlie_Parker", "dEllington", "jColtrane", "mDavis", 
          "dGillespie", "lArmstrong", "cHawkins", "cMingus", "query")

# we will include the query in our corpus, so when we later look use cosine similarity we it will be included. 
query <- c("famous jazz saxophonist born in kansas who played bebop and latin")
corp <- c(Corpus(VectorSource(cParker)), 
          Corpus(VectorSource(dEllington)), 
          Corpus(VectorSource(jColtrane)),
          Corpus(VectorSource(mDavis)), 
          Corpus(VectorSource(dGillespie)),
          Corpus(VectorSource(lArmstrong)),
          Corpus(VectorSource(cHawkins)),
          Corpus(VectorSource(cMingus)),
          Corpus(VectorSource(query)))

## clean corpus
CleanCorp <- tm_map(corp, removeNumbers)
CleanCorp <- tm_map(CleanCorp, removePunctuation)
CleanCorp <- tm_map(CleanCorp, content_transformer(tolower))
CleanCorp <- tm_map(CleanCorp, removeWords, stopwords("english")) 
CleanCorp <- tm_map(CleanCorp, stemDocument, language="en")
```

## Word Cloud

For fun, let's make a quick word cloud of the top terms in our corpus before converting to a term document matrix. 

```{r}
wordcloud(CleanCorp, max.words = 100, random.order = FALSE, colors=brewer.pal(5,"Set1"))
```

## Term Document Matrix

Here we will create the Term Document Matrix and search for our query words.  The TDF is much larger than appears, as it has counts of all the words by document.   NOTE:   A document in this corpus = each jazz musician's Wiki page.

```{r}
## create TDM
tdm <- TermDocumentMatrix(CleanCorp)
tdm$dimnames$Docs <- list

## Since we're mostly going to review our query, we don't need to remove Sparse Terms
#tdm <- removeSparseTerms(tdm, 1-(3/length(CleanCorp)))
```

# TF-IDF

Our goal is to search for "famous jazz saxophonist born in kansas who played bebop and latin".   First we'll look only at TF.  Then we'll use the TermDocumentMatrix weighting function to calculate and display TF-IDF. 

```{r}
search <- c("famous","jazz", "saxophonist", "born", "kansa", "play", "bebop", "latin")
r1 <- inspect(tdm[search[search %in% Terms(tdm)], dimnames(tdm)$Docs])

tfidf <- TermDocumentMatrix(CleanCorp, control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tfidf$dimnames$Docs <- list

r2 <- inspect(tfidf[search[search %in% Terms(tfidf)], dimnames(tfidf)$Docs])
```

# Conclusion

We use the cosine function from the lsa library to find the cosine similarity of the documents.    This is ultimately why we added our query text to the corpus, so we could then compare the others to it in the resulting matrix.  
```{r}
# for fun, let's look at all of the results
final <- cosine(r2)
final

#now we subset so we only see them each compared to the query 
final2 <- final[1:(dim(final)[1] -1),ncol(final)]
pfinal <- final2[order(final2, decreasing=TRUE)]
pfinal <- round(pfinal, 4)
p <- barplot(pfinal, main="Cosine Similarity to Query", las=2) 
text(x = p, y = pfinal, label = pfinal, pos=1.2, cex = 0.8)
```

We can see from the above plot that our query text most resembles the Wikipedia text for Charlie Parker.    I added Coleman Hawkins, since he is also a sax player from Kansas, but we can see that Bird still comes out ahead ("famous" plays a part).  